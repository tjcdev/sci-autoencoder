{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Hybird Recommender (with content in the first layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from time import gmtime, strftime\n",
    "\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import precision_recall_fscore_support, mean_squared_error, average_precision_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import keras.backend as K\n",
    "from scipy import sparse\n",
    "from scipy.sparse import vstack\n",
    "\n",
    "# Content based recommender imports\n",
    "module_path = os.path.abspath(os.path.join('../../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from src.models.recommenders.content_recommender import ContentRecommender\n",
    "from gensim.models import doc2vec\n",
    "from collections import namedtuple\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from keras.models import Model\n",
    "\n",
    "sys.path.append('../../data')\n",
    "sys.path.append('../../src/models')\n",
    "from recommenders.cf_recommender import CFRecommender\n",
    "from autoencoders import hyb1, hyb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "field = 'description'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Collaborative Filtering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_users_projects():\n",
    "    cf = pd.read_pickle('../../data/processed/new_cf_projects.pkl')\n",
    "    #cf = pd.read_pickle('data/processed/cf_profiles.pkl')\n",
    "    train_x = sparse.load_npz(\"../../data/processed/new_train_sparse.npz\")\n",
    "    val_x = sparse.load_npz(\"../../data/processed/new_val_sparse.npz\")\n",
    "    test_x = sparse.load_npz(\"../../data/processed/new_test_sparse.npz\")\n",
    "    train_labels = cf\n",
    "    val_labels = cf\n",
    "    test_labels = cf\n",
    "    return train_labels, train_x, val_labels, val_x, test_labels, test_x\n",
    "\n",
    "def load_profile_labels():\n",
    "    cf_profiles = pd.read_pickle('../../data/processed/new_cf_profiles.pkl')\n",
    "    return cf_profiles\n",
    "\n",
    "# Load out time consistent collaborative filtering data\n",
    "train_labels, train_x, val_labels, val_x, test_labels, test_x = load_users_projects()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Content Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_projects_tfidf(field):\n",
    "    # Load the full project data from the pickle file\n",
    "    content_projects = pd.read_pickle(\"../../data/processed/cf_projects_data\")\n",
    "\n",
    "    # Get the TF-IDF for the description fields\n",
    "    v = TfidfVectorizer(max_features=3000)\n",
    "    desc_idf = v.fit_transform(content_projects[field])\n",
    "\n",
    "    # Train/Val/Test Split\n",
    "    content_test_split_idx = int(np.floor(desc_idf.shape[0] * 0.8))\n",
    "    content_val_split_idx = int(content_test_split_idx * 0.9)\n",
    "\n",
    "    content_train_x = desc_idf[:content_val_split_idx]\n",
    "    content_val_x = desc_idf[content_val_split_idx:content_test_split_idx]\n",
    "    content_test_x = desc_idf[content_test_split_idx:]\n",
    "\n",
    "    content_train_labels_idx = np.arange(0, content_val_split_idx)\n",
    "    content_val_labels_idx = np.arange(content_val_split_idx, content_test_split_idx)\n",
    "    content_test_labels_idx = np.arange(content_test_split_idx, desc_idf.shape[0])\n",
    "\n",
    "    content_train_labels = pd.DataFrame(content_projects['project_id'].iloc[:content_val_split_idx], index=content_train_labels_idx)\n",
    "    content_val_labels = pd.DataFrame(content_projects['project_id'].iloc[content_val_split_idx:content_test_split_idx], index=content_val_labels_idx)\n",
    "    content_test_labels = pd.DataFrame(content_projects['project_id'].iloc[content_test_split_idx:], index=content_test_labels_idx)\n",
    "\n",
    "    return content_train_labels, content_train_x, content_val_labels, content_val_x, content_test_labels, content_test_x\n",
    "\n",
    "project_train_labels, project_train_x, project_val_labels, project_val_x, project_test_labels, project_test_x = load_projects_tfidf(field)\n",
    "\n",
    "# Generate the embeddings\n",
    "x = vstack([project_train_x, project_val_x, project_test_x]).tocsr()\n",
    "x_projects = project_train_labels + project_val_labels + project_test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First create the users TF-IDF vector -- should be shape (3000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_tf_idf = None\n",
    "for user_index in range(0, train_x.shape[1]):\n",
    "    user_project_idx = np.nonzero(train_x[:, user_index])[0]\n",
    "    user_tf_idf = np.squeeze(np.asarray(x[user_project_idx].sum(axis=0)))\n",
    "    users_tf_idf = vstack([users_tf_idf, user_tf_idf])\n",
    "users_tf_idf = sparse.csr_matrix(users_tf_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/thomascartwright/miniconda3/envs/cdea/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py:423: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/thomascartwright/miniconda3/envs/cdea/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../../src/models/autoencoders/hyb2.py:20: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(32, kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg...)`\n",
      "  h_item = Dense(K, W_regularizer=l2(l), b_regularizer=l2(l))(h_item)\n",
      "../../src/models/autoencoders/hyb2.py:24: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(32, kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg...)`\n",
      "  h_content = Dense(K, W_regularizer=l2(l), b_regularizer=l2(l))(content_item)\n",
      "../../src/models/autoencoders/hyb2.py:25: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1024, kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg...)`\n",
      "  h_content_1024 = Dense(1024, W_regularizer=l2(l), b_regularizer=l2(l))(content_item)\n",
      "../../src/models/autoencoders/hyb2.py:26: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(512, kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg...)`\n",
      "  h_content_512 = Dense(512, W_regularizer=l2(l), b_regularizer=l2(l))(content_item)\n",
      "../../src/models/autoencoders/hyb2.py:30: UserWarning: Update your `Embedding` call to the Keras 2 API: `Embedding(input_dim=1032, output_dim=32, input_length=1, name=\"embedding_layer\", embeddings_regularizer=<keras.reg...)`\n",
      "  h_user = Embedding(input_dim=U, output_dim=K, input_length=1, W_regularizer=l2(l), name='embedding_layer')(x_user)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "x_item (InputLayer)             (None, 1021)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "x_user (InputLayer)             (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1021)         0           x_item[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_layer (Embedding)     (None, 1, 32)        33024       x_user[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "content_item (InputLayer)       (None, 3000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           32704       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 32)           0           embedding_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           96032       content_item[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32)           0           dense_1[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32)           0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1024)         33792       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1024)         0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1024)         3073024     content_item[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 1024)         0           dropout_2[0][0]                  \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 512)          524800      add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 512)          0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 512)          1536512     content_item[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 512)          0           dropout_3[0][0]                  \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 512)          262656      add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 512)          0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 512)          0           dropout_4[0][0]                  \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 512)          262656      add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 512)          262656      dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 1024)         525312      dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1021)         1046525     dense_10[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 7,689,693\n",
      "Trainable params: 7,689,693\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../../src/models/autoencoders/hyb2.py:58: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n",
      "  return Model(input=[x_item, content_item, x_user], output=decoded)\n"
     ]
    }
   ],
   "source": [
    "U = train_x.shape[1]\n",
    "I = train_x.shape[0]\n",
    "embedding_size = 32\n",
    "q = 0.8\n",
    "\n",
    "# Create our autoencoder model\n",
    "model = hyb2.create(I=I, U=U, K=embedding_size,\n",
    "                    hidden_activation='relu', output_activation='sigmoid', q=q, l=0.001)\n",
    "model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train our autoencoder\n",
    "train_x_t = train_x.T\n",
    "val_x_t = val_x.T\n",
    "test_x_t = test_x.T\n",
    "\n",
    "train_val_x = train_x_t + val_x_t\n",
    "train_test_x = train_x_t + test_x_t\n",
    "\n",
    "users = np.arange(0, train_x_t.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train_x shape is (1032, 1021)\n",
      "The x_projects shape is (1032,)\n",
      "The user_tf_idf shape is (1032, 3000)\n"
     ]
    }
   ],
   "source": [
    "print('The train_x shape is %s' % (str(train_x_t.shape)))\n",
    "print('The x_projects shape is %s' % (str(users.shape)))\n",
    "print('The user_tf_idf shape is %s' % (str(users_tf_idf.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomascartwright/miniconda3/envs/cdea/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/thomascartwright/miniconda3/envs/cdea/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 1032 samples, validate on 1032 samples\n",
      "Epoch 1/10\n",
      "1032/1032 [==============================] - 9s 8ms/step - loss: 1.0728 - val_loss: 0.1430\n",
      "Epoch 2/10\n",
      "1032/1032 [==============================] - 7s 6ms/step - loss: 0.0544 - val_loss: 0.0274\n",
      "Epoch 3/10\n",
      "1032/1032 [==============================] - 7s 7ms/step - loss: 0.0201 - val_loss: 0.0201\n",
      "Epoch 4/10\n",
      "1032/1032 [==============================] - 7s 7ms/step - loss: 0.0166 - val_loss: 0.0189\n",
      "Epoch 5/10\n",
      "1032/1032 [==============================] - 7s 7ms/step - loss: 0.0159 - val_loss: 0.0185\n",
      "Epoch 6/10\n",
      "1032/1032 [==============================] - 7s 7ms/step - loss: 0.0156 - val_loss: 0.0183\n",
      "Epoch 7/10\n",
      "1032/1032 [==============================] - 7s 6ms/step - loss: 0.0155 - val_loss: 0.0182\n",
      "Epoch 8/10\n",
      "1032/1032 [==============================] - 7s 7ms/step - loss: 0.0154 - val_loss: 0.0182\n",
      "Epoch 9/10\n",
      "1032/1032 [==============================] - 7s 7ms/step - loss: 0.0154 - val_loss: 0.0182\n",
      "Epoch 10/10\n",
      "1032/1032 [==============================] - 7s 7ms/step - loss: 0.0154 - val_loss: 0.0182\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=[train_x_t, users_tf_idf, users], y=train_x_t,\n",
    "                    batch_size=32, nb_epoch=10, verbose=1,\n",
    "                    validation_data=[[train_x_t, users_tf_idf, users], train_val_x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_idx = 0\n",
    "profile_col = np.squeeze(np.asarray(train_x.getcol(profile_idx).todense())).reshape(1,-1)\n",
    "labels = np.asarray(train_labels.index)\n",
    "this_users_tf_idf = np.squeeze(np.asarray(users_tf_idf.getrow(profile_idx).todense())).reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction for \n",
    "predictions = model.predict([profile_col, this_users_tf_idf, labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "recommender = CFRecommender(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Top-K Recommendataions\n",
    "recommendations = recommender.top_projects(profile_col, predictions, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = recommender.generate_y(recommendations, train_labels, test_x.getcol(profile_idx), val_x=val_x.getcol(profile_idx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get precision and recall\n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_true, y_pred, average='binary', pos_label=1)\n",
    "avg_precision = average_precision_score(y_true, predictions.reshape(y_true.shape), average='weighted', pos_label=1)\n",
    "rmse = math.sqrt(mean_squared_error(y_true, predictions.reshape(y_true.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0019588638589618022"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04425905397725761"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
