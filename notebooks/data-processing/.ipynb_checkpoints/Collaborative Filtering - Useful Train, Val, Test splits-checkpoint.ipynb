{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import scipy.sparse as sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_progress(sequence, every=None, size=None, name='Items'):\n",
    "    from ipywidgets import IntProgress, HTML, VBox\n",
    "    from IPython.display import display\n",
    "\n",
    "    is_iterator = False\n",
    "    if size is None:\n",
    "        try:\n",
    "            size = len(sequence)\n",
    "        except TypeError:\n",
    "            is_iterator = True\n",
    "    if size is not None:\n",
    "        if every is None:\n",
    "            if size <= 200:\n",
    "                every = 1\n",
    "            else:\n",
    "                every = int(size / 200)     # every 0.5%\n",
    "    else:\n",
    "        assert every is not None, 'sequence is iterator, set every'\n",
    "\n",
    "    if is_iterator:\n",
    "        progress = IntProgress(min=0, max=1, value=1)\n",
    "        progress.bar_style = 'info'\n",
    "    else:\n",
    "        progress = IntProgress(min=0, max=size, value=0)\n",
    "    label = HTML()\n",
    "    box = VBox(children=[label, progress])\n",
    "    display(box)\n",
    "\n",
    "    index = 0\n",
    "    try:\n",
    "        for index, record in enumerate(sequence, 1):\n",
    "            if index == 1 or index % every == 0:\n",
    "                if is_iterator:\n",
    "                    label.value = '{name}: {index} / ?'.format(\n",
    "                        name=name,\n",
    "                        index=index\n",
    "                    )\n",
    "                else:\n",
    "                    progress.value = index\n",
    "                    label.value = u'{name}: {index} / {size}'.format(\n",
    "                        name=name,\n",
    "                        index=index,\n",
    "                        size=size\n",
    "                    )\n",
    "            yield record\n",
    "    except:\n",
    "        progress.bar_style = 'danger'\n",
    "        raise\n",
    "    else:\n",
    "        progress.bar_style = 'success'\n",
    "        progress.value = index\n",
    "        label.value = \"{name}: {index}\".format(\n",
    "            name=name,\n",
    "            index=str(index or '?')\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "participations = pd.read_pickle('../../data/raw/participation_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove participations with bad types\n",
    "types = participations.groupby('type').size().reset_index()\n",
    "participations = participations[participations['type'] != 'Removed a bookmark']\n",
    "participations = participations[participations['type'] != 'Removed from dashboard']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove participations with NaN project_id\n",
    "participations = participations[np.isfinite(participations['project'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group by profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to\n",
    "1. Group by profile to get all profiles with at least 8 unique project interactions\n",
    "2. Order the participations by 'when'\n",
    "3. Get number of unique participations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So we have a total of 1032 profiles that have more than 8 project interactions\n"
     ]
    }
   ],
   "source": [
    "# Get the profile ids for profiles that have more than 8 unique project interactions\n",
    "profiles = participations.groupby('profile')['project'].nunique()\n",
    "active_profiles = profiles[profiles >= 8]\n",
    "print('So we have a total of %d profiles that have more than 8 project interactions' % (len(active_profiles)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So we have a total of 164803 participations\n"
     ]
    }
   ],
   "source": [
    "# Only select profiles that are in active_probiles\n",
    "active_participations = participations[participations['profile'].isin(active_profiles.index)]\n",
    "print('So we have a total of %d participations' % (len(active_participations)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So our train_grouping has 131842 participations\n"
     ]
    }
   ],
   "source": [
    "# Get the first 80% of participations from all profile groups\n",
    "grouping = active_participations.groupby('profile').apply(lambda x: x.sort_values('when'))\n",
    "train_grouping = grouping.apply(lambda x: x.head(int(len(x)*0.8)))\n",
    "print('So our train_grouping has %d participations' % (len(train_grouping)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So our val_test_grouping has 32960 participations\n"
     ]
    }
   ],
   "source": [
    "val_test_grouping = grouping.apply(lambda x: x.tail(int(len(x)*0.2)))\n",
    "print('So our val_test_grouping has %d participations' % (len(val_test_grouping)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create our participation dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So our train_cf has 131842 participations\n"
     ]
    }
   ],
   "source": [
    "# Create the training dataframe\n",
    "train_participations = train_grouping.reset_index(drop=True)\n",
    "print('So our train_cf has %d participations' % (len(train_cf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So our val_test_cf has 32960 participations\n",
      "The length of our mask: 32960\n",
      "Our validation set contains: 16518 participations\n",
      "Our test set contains: 16442 participations\n"
     ]
    }
   ],
   "source": [
    "# Create our validation and testing dataframes\n",
    "val_test_participations = val_test_grouping.reset_index(drop=True)\n",
    "print('So our val_test_cf has %d participations' % (len(val_test_cf)))\n",
    "\n",
    "# Randomly split our val_test set into validation and test set\n",
    "mask = np.random.rand(len(val_test_participations)) <= 0.5\n",
    "print('The length of our mask: %d' % (len(mask)))\n",
    "\n",
    "val_participations = val_test_participations[mask]\n",
    "test_participations = val_test_participations[~mask]\n",
    "print('Our validation set contains: %d participations' % (len(val_participations)))\n",
    "print('Our test set contains: %d participations' % (len(test_participations)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create our CF Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 1781 projects in our dataset\n"
     ]
    }
   ],
   "source": [
    "# Load in our projects dataset\n",
    "projects = pd.read_pickle('../../data/processed/project_data')\n",
    "project_ids = list(set(projects['project_id']))\n",
    "project_ids.sort()\n",
    "print('We have %d projects in our dataset' % (len(projects)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles = active_profiles.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pandas dataframe with profiles as columns and projects as rows\n",
    "cf = pd.DataFrame(columns=profiles, index=project_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1781, 1032)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all values in the dataframe to zero\n",
    "for col in cf.columns:\n",
    "    cf[col].values[:] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe for Train, Validation and Test\n",
    "train_cf = cf.copy()\n",
    "val_cf = cf.copy()\n",
    "test_cf = cf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fe9df9e9d904cc1891a1f488456ff4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=''), IntProgress(value=0, max=1029)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate the train_cf matrix\n",
    "train_projects_profiles = train_participations.groupby('project')['profile'].apply(set)\n",
    "train_max_id = max(train_projects_profiles.index)\n",
    "\n",
    "train_project_ids = [project_id for project_id in train_projects_profiles.index if project_id in train_cf.index]\n",
    "\n",
    "for project_id in log_progress(train_project_ids):\n",
    "    train_profiles_list = list(train_projects_profiles[project_id])\n",
    "    project_id = int(project_id)\n",
    "\n",
    "    train_cf.loc[project_id].loc[train_profiles_list] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb476861a12f45fb8c2742462f94d31a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=''), IntProgress(value=0, max=593)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate the val_cf matrix\n",
    "val_projects_profiles = val_participations.groupby('project')['profile'].apply(set)\n",
    "val_max_id = max(val_projects_profiles.index)\n",
    "\n",
    "val_project_ids = [project_id for project_id in val_projects_profiles.index if project_id in val_cf.index]\n",
    "\n",
    "for project_id in log_progress(val_project_ids):\n",
    "    val_profiles_list = list(val_projects_profiles[project_id])\n",
    "    project_id = int(project_id)\n",
    "\n",
    "    val_cf.loc[project_id].loc[val_profiles_list] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d70efa81e0549f09c6da7bb52ead8e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=''), IntProgress(value=0, max=603)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate the test_cf matrix\n",
    "test_projects_profiles = test_participations.groupby('project')['profile'].apply(set)\n",
    "test_max_id = max(test_projects_profiles.index)\n",
    "\n",
    "test_project_ids = [project_id for project_id in test_projects_profiles.index if project_id in test_cf.index]\n",
    "\n",
    "for project_id in log_progress(test_project_ids):\n",
    "    test_profiles_list = list(test_projects_profiles[project_id])\n",
    "    project_id = int(project_id)\n",
    "\n",
    "    test_cf.loc[project_id].loc[test_profiles_list] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our train_cf has size (1781, 1032)\n",
      "Our val_cf has size (1781, 1032)\n",
      "Our test_cf has size (1781, 1032)\n"
     ]
    }
   ],
   "source": [
    "print('Our train_cf has size (%d, %d)' % (train_cf.shape[0], train_cf.shape[1]))\n",
    "print('Our val_cf has size (%d, %d)' % (val_cf.shape[0], val_cf.shape[1]))\n",
    "print('Our test_cf has size (%d, %d)' % (test_cf.shape[0], test_cf.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove any projects or profiles that have all zero values in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 152 profiles that have interacted with no projects in the training set\n"
     ]
    }
   ],
   "source": [
    "# Find zero columns in the training set\n",
    "empty_profiles = train_cf.columns[(train_cf == 0).all()]\n",
    "print('We have %d profiles that have interacted with no projects in the training set' % (len(empty_profiles)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 752 projects that have had no profile interactions in the training set\n"
     ]
    }
   ],
   "source": [
    "# Find zero rows\n",
    "empty_projects = train_cf[train_cf.eq(0).all(1)].index\n",
    "print('We have %d projects that have had no profile interactions in the training set' % (len(empty_projects)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our train_cf has size (1781, 1032)\n",
      "Our val_cf has size (1781, 1032)\n",
      "Our test_cf has size (1781, 1032)\n"
     ]
    }
   ],
   "source": [
    "print('Our train_cf has size (%d, %d)' % (train_cf.shape[0], train_cf.shape[1]))\n",
    "print('Our val_cf has size (%d, %d)' % (val_cf.shape[0], val_cf.shape[1]))\n",
    "print('Our test_cf has size (%d, %d)' % (test_cf.shape[0], test_cf.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Remove columns from dataframes\n",
    "train_cf = train_cf.drop(columns=empty_profiles)\n",
    "val_cf = val_cf.drop(columns=empty_profiles)\n",
    "test_cf = test_cf.drop(columns=empty_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Remove rows from dataframes\n",
    "train_cf = train_cf.drop(empty_projects)\n",
    "val_cf = val_cf.drop(empty_projects)\n",
    "test_cf = test_cf.drop(empty_projects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our train_cf has size (1029, 880)\n",
      "Our val_cf has size (1029, 880)\n",
      "Our test_cf has size (1029, 880)\n"
     ]
    }
   ],
   "source": [
    "print('Our train_cf has size (%d, %d)' % (train_cf.shape[0], train_cf.shape[1]))\n",
    "print('Our val_cf has size (%d, %d)' % (val_cf.shape[0], val_cf.shape[1]))\n",
    "print('Our test_cf has size (%d, %d)' % (test_cf.shape[0], test_cf.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cf.to_pickle('../../data/raw/train_cf.pkl')\n",
    "val_cf.to_pickle('../../data/raw/val_cf.pkl')\n",
    "test_cf.to_pickle('../../data/raw/test_cf.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Sparse Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sparse = sparse.csr_matrix(train_cf.values.astype(int))\n",
    "sparse.save_npz('train_sparse.npz', train_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_sparse = sparse.csr_matrix(val_cf.values.astype(int))\n",
    "sparse.save_npz('val_sparse.npz', val_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sparse = sparse.csr_matrix(test_cf.values.astype(int))\n",
    "sparse.save_npz('test_sparse.npz', test_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
