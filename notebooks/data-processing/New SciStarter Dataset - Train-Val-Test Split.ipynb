{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import scipy.sparse as sparse\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_progress(sequence, every=None, size=None, name='Items'):\n",
    "    from ipywidgets import IntProgress, HTML, VBox\n",
    "    from IPython.display import display\n",
    "\n",
    "    is_iterator = False\n",
    "    if size is None:\n",
    "        try:\n",
    "            size = len(sequence)\n",
    "        except TypeError:\n",
    "            is_iterator = True\n",
    "    if size is not None:\n",
    "        if every is None:\n",
    "            if size <= 200:\n",
    "                every = 1\n",
    "            else:\n",
    "                every = int(size / 200)     # every 0.5%\n",
    "    else:\n",
    "        assert every is not None, 'sequence is iterator, set every'\n",
    "\n",
    "    if is_iterator:\n",
    "        progress = IntProgress(min=0, max=1, value=1)\n",
    "        progress.bar_style = 'info'\n",
    "    else:\n",
    "        progress = IntProgress(min=0, max=size, value=0)\n",
    "    label = HTML()\n",
    "    box = VBox(children=[label, progress])\n",
    "    display(box)\n",
    "\n",
    "    index = 0\n",
    "    try:\n",
    "        for index, record in enumerate(sequence, 1):\n",
    "            if index == 1 or index % every == 0:\n",
    "                if is_iterator:\n",
    "                    label.value = '{name}: {index} / ?'.format(\n",
    "                        name=name,\n",
    "                        index=index\n",
    "                    )\n",
    "                else:\n",
    "                    progress.value = index\n",
    "                    label.value = u'{name}: {index} / {size}'.format(\n",
    "                        name=name,\n",
    "                        index=index,\n",
    "                        size=size\n",
    "                    )\n",
    "            yield record\n",
    "    except:\n",
    "        progress.bar_style = 'danger'\n",
    "        raise\n",
    "    else:\n",
    "        progress.bar_style = 'success'\n",
    "        progress.value = index\n",
    "        label.value = \"{name}: {index}\".format(\n",
    "            name=name,\n",
    "            index=str(index or '?')\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "participations = pd.read_json('../../data/raw/new-sci-participation-data.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the participations into train/val/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42159"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(participations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_types = participations.groupby('type')['project'].agg('count').reset_index()\n",
    "interaction_types = interaction_types.rename(index=str, columns={\"project\": \"num_interactions\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>num_interactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Classification / Transcription</td>\n",
       "      <td>12074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data collection</td>\n",
       "      <td>23717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Joined the project</td>\n",
       "      <td>3020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Participated</td>\n",
       "      <td>3348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             type  num_interactions\n",
       "0  Classification / Transcription             12074\n",
       "1                 Data collection             23717\n",
       "2              Joined the project              3020\n",
       "3                    Participated              3348"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interaction_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove participations with bad types\n",
    "types = participations.groupby('type').size().reset_index()\n",
    "participations = participations[participations['type'] != 'Removed a bookmark']\n",
    "participations = participations[participations['type'] != 'Removed from dashboard']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our new dataset has 42159 participations in it\n"
     ]
    }
   ],
   "source": [
    "print('Our new dataset has %d participations in it' % (len(participations)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove participations with NaN project_id\n",
    "participations = participations[np.isfinite(participations['project'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4782"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(participations['profile']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "357"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(participations[participations['project'] == 92])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group by profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to\n",
    "1. Group by profile to get all profiles with at least 8 unique project interactions\n",
    "2. Order the participations by 'when'\n",
    "3. Get number of unique participations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So we have a total of 896 profiles that have more than 8 project interactions\n"
     ]
    }
   ],
   "source": [
    "# Get the profile ids for profiles that have more than 8 unique project interactions\n",
    "profiles = participations.groupby('profile')['project'].nunique()\n",
    "active_profiles = profiles[profiles >= 2]\n",
    "print('So we have a total of %d profiles that have more than 8 project interactions' % (len(active_profiles)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3013392857142856"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(active_profiles.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So we have a total of 17658 participations\n"
     ]
    }
   ],
   "source": [
    "# Only select profiles that are in active_probiles\n",
    "active_participations = participations[participations['profile'].isin(active_profiles.index)]\n",
    "print('So we have a total of %d participations' % (len(active_participations)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our grouping has 896 profiles\n"
     ]
    }
   ],
   "source": [
    "# Get the first 80% of participations from all profile groups\n",
    "grouping = active_participations.groupby('profile') #.apply(lambda x: x)\n",
    "print('Our grouping has %d profiles' % (len(grouping)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So our train_grouping has 13691 participations\n"
     ]
    }
   ],
   "source": [
    "train_grouping = grouping.apply(lambda x: x.sort_values('when', ascending=True).head(int(len(x)*0.8)))\n",
    "print('So our train_grouping has %d participations' % (len(train_grouping)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So our val_test_grouping has 3145 participations\n"
     ]
    }
   ],
   "source": [
    "val_test_grouping = grouping.apply(lambda x: x.sort_values('when', ascending=True).tail(int(len(x)*0.2)))\n",
    "print('So our val_test_grouping has %d participations' % (len(val_test_grouping)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create our participation dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So our train_cf has 13691 participations\n"
     ]
    }
   ],
   "source": [
    "# Create the training dataframe\n",
    "train_participations = train_grouping.reset_index(drop=True)\n",
    "print('So our train_cf has %d participations' % (len(train_participations)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So our val_test_cf has 3145 participations\n",
      "The length of our mask: 3145\n",
      "Our validation set contains: 1571 participations\n",
      "Our test set contains: 1574 participations\n"
     ]
    }
   ],
   "source": [
    "# Create our validation and testing dataframes\n",
    "val_test_participations = val_test_grouping.reset_index(drop=True)\n",
    "print('So our val_test_cf has %d participations' % (len(val_test_participations)))\n",
    "\n",
    "# Randomly split our val_test set into validation and test set\n",
    "mask = np.random.rand(len(val_test_participations)) <= 0.5\n",
    "print('The length of our mask: %d' % (len(mask)))\n",
    "\n",
    "val_participations = val_test_participations[mask]\n",
    "test_participations = val_test_participations[~mask]\n",
    "print('Our validation set contains: %d participations' % (len(val_participations)))\n",
    "print('Our test set contains: %d participations' % (len(test_participations)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create our CF Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 1781 projects in our dataset\n"
     ]
    }
   ],
   "source": [
    "# Load in our projects dataset\n",
    "projects = pd.read_pickle('../../data/processed/project_data')\n",
    "project_ids = list(set(projects['project_id']))\n",
    "project_ids.sort()\n",
    "print('We have %d projects in our dataset' % (len(projects)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles = active_profiles.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And we have 896 profiles in our dataset\n"
     ]
    }
   ],
   "source": [
    "print('And we have %d profiles in our dataset' % (len(profiles)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pandas dataframe with profiles as columns and projects as rows\n",
    "cf = pd.DataFrame(columns=profiles, index=project_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1781, 896)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all values in the dataframe to zero\n",
    "for col in cf.columns:\n",
    "    cf[col].values[:] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe for Train, Validation and Test\n",
    "train_cf = cf.copy()\n",
    "val_cf = cf.copy()\n",
    "test_cf = cf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca8e78161c09454dbd35c44a211517dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=''), IntProgress(value=0, max=27)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate the train_cf matrix\n",
    "train_projects_profiles = train_participations.groupby('project')['profile'].apply(set)\n",
    "train_max_id = max(train_projects_profiles.index)\n",
    "\n",
    "train_project_ids = [project_id for project_id in train_projects_profiles.index if project_id in train_cf.index]\n",
    "\n",
    "for project_id in log_progress(train_project_ids):\n",
    "    train_profiles_list = list(train_projects_profiles[project_id])\n",
    "    project_id = int(project_id)\n",
    "\n",
    "    train_cf.loc[project_id].loc[train_profiles_list] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our training dataset has 437 interactions in it\n"
     ]
    }
   ],
   "source": [
    "print('Our training dataset has %d interactions in it' % (np.count_nonzero(train_cf.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c7cb2a88d7347fb99d48b0808bd2690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=''), IntProgress(value=0, max=12)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate the val_cf matrix\n",
    "val_projects_profiles = val_participations.groupby('project')['profile'].apply(set)\n",
    "val_max_id = max(val_projects_profiles.index)\n",
    "\n",
    "val_project_ids = [project_id for project_id in val_projects_profiles.index if project_id in val_cf.index]\n",
    "\n",
    "for project_id in log_progress(val_project_ids):\n",
    "    val_profiles_list = list(val_projects_profiles[project_id])\n",
    "    project_id = int(project_id)\n",
    "\n",
    "    val_cf.loc[project_id].loc[val_profiles_list] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our validation dataset has 70 interactions in it\n"
     ]
    }
   ],
   "source": [
    "print('Our validation dataset has %d interactions in it' % (np.count_nonzero(val_cf.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dc306ab125b4a8fa4fc8ba60a2193d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=''), IntProgress(value=0, max=11)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate the test_cf matrix\n",
    "test_projects_profiles = test_participations.groupby('project')['profile'].apply(set)\n",
    "test_max_id = max(test_projects_profiles.index)\n",
    "\n",
    "test_project_ids = [project_id for project_id in test_projects_profiles.index if project_id in test_cf.index]\n",
    "\n",
    "for project_id in log_progress(test_project_ids):\n",
    "    test_profiles_list = list(test_projects_profiles[project_id])\n",
    "    project_id = int(project_id)\n",
    "\n",
    "    test_cf.loc[project_id].loc[test_profiles_list] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our test dataset has 68 interactions in it\n"
     ]
    }
   ],
   "source": [
    "print('Our test dataset has %d interactions in it' % (np.count_nonzero(test_cf.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our train_cf has size (1781, 896)\n",
      "Our val_cf has size (1781, 896)\n",
      "Our test_cf has size (1781, 896)\n"
     ]
    }
   ],
   "source": [
    "print('Our train_cf has size (%d, %d)' % (train_cf.shape[0], train_cf.shape[1]))\n",
    "print('Our val_cf has size (%d, %d)' % (val_cf.shape[0], val_cf.shape[1]))\n",
    "print('Our test_cf has size (%d, %d)' % (test_cf.shape[0], test_cf.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove any projects or profiles that have all zero values in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 552 profiles that have interacted with no projects in the training set\n"
     ]
    }
   ],
   "source": [
    "# Find zero columns in the training set\n",
    "empty_profiles = train_cf.columns[(train_cf == 0).all()]\n",
    "print('We have %d profiles that have interacted with no projects in the training set' % (len(empty_profiles)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 1754 projects that have had no profile interactions in the training set\n",
      "We have 1754 projects that have had no profile interactions in all sets\n"
     ]
    }
   ],
   "source": [
    "# Find zero rows\n",
    "empty_projects_train = train_cf[train_cf.eq(0).all(1)].index\n",
    "empty_projects_val = val_cf[val_cf.eq(0).all(1)].index\n",
    "empty_projects_test = test_cf[test_cf.eq(0).all(1)].index\n",
    "\n",
    "empty_projects = reduce(np.intersect1d, (empty_projects_train, empty_projects_val, empty_projects_test))\n",
    "\n",
    "print('We have %d projects that have had no profile interactions in the training set' % (len(empty_projects_train)))\n",
    "print('We have %d projects that have had no profile interactions in all sets' % (len(empty_projects)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our train_cf has size (1781, 896)\n",
      "Our val_cf has size (1781, 896)\n",
      "Our test_cf has size (1781, 896)\n"
     ]
    }
   ],
   "source": [
    "print('Our train_cf has size (%d, %d)' % (train_cf.shape[0], train_cf.shape[1]))\n",
    "print('Our val_cf has size (%d, %d)' % (val_cf.shape[0], val_cf.shape[1]))\n",
    "print('Our test_cf has size (%d, %d)' % (test_cf.shape[0], test_cf.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Remove columns from dataframes\n",
    "clean_train_cf = train_cf.drop(columns=empty_profiles)\n",
    "clean_val_cf = val_cf.drop(columns=empty_profiles)\n",
    "clean_test_cf = test_cf.drop(columns=empty_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Remove rows from dataframes\n",
    "clean_train_cf = clean_train_cf.drop(empty_projects)\n",
    "clean_val_cf = clean_val_cf.drop(empty_projects)\n",
    "clean_test_cf = clean_test_cf.drop(empty_projects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our train_cf has size (27, 344)\n",
      "Our val_cf has size (27, 344)\n",
      "Our test_cf has size (27, 344)\n"
     ]
    }
   ],
   "source": [
    "print('Our train_cf has size (%d, %d)' % (clean_train_cf.shape[0], clean_train_cf.shape[1]))\n",
    "print('Our val_cf has size (%d, %d)' % (clean_val_cf.shape[0], clean_val_cf.shape[1]))\n",
    "print('Our test_cf has size (%d, %d)' % (clean_test_cf.shape[0], clean_test_cf.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our training dataset has 437 interactions in it\n",
      "Our validation dataset has 65 interactions in it\n",
      "Our test dataset has 62 interactions in it\n"
     ]
    }
   ],
   "source": [
    "print('Our training dataset has %d interactions in it' % (np.count_nonzero(clean_train_cf.values)))\n",
    "print('Our validation dataset has %d interactions in it' % (np.count_nonzero(clean_val_cf.values)))\n",
    "print('Our test dataset has %d interactions in it' % (np.count_nonzero(clean_test_cf.values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train_cf.to_pickle('../../data/raw/new_train_cf.pkl')\n",
    "clean_val_cf.to_pickle('../../data/raw/new_val_cf.pkl')\n",
    "clean_test_cf.to_pickle('../../data/raw/new_test_cf.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sparse = sparse.csr_matrix(clean_train_cf.values.astype(int))\n",
    "sparse.save_npz('../../data/raw/new_train_sparse.npz', train_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_sparse = sparse.csr_matrix(clean_val_cf.values.astype(int))\n",
    "sparse.save_npz('../../data/raw/new_val_sparse.npz', val_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sparse = sparse.csr_matrix(clean_test_cf.values.astype(int))\n",
    "sparse.save_npz('../../data/raw/new_test_sparse.npz', test_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new dataframes for profiles and projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cf = pd.read_pickle('../../data/processed/new_train_cf.pkl')\n",
    "profile_ids = train_cf.columns\n",
    "train_labels = pd.DataFrame(profile_ids, index=np.arange(0, len(profile_ids)))\n",
    "train_labels.to_pickle('../../data/processed/new_cf_profiles.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cf = pd.read_pickle('../../data/processed/new_train_cf.pkl')\n",
    "project_ids = train_cf.index\n",
    "train_labels = pd.DataFrame(project_ids, index=np.arange(0, len(project_ids)))\n",
    "train_labels.to_pickle('../../data/processed/new_cf_projects.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
